# who_made_it
This tries to determine whether a given poem is real or was generated by AI or by an amateur

The included notebook uses fine tuning to construct an Open AI model that determines whether a given poem is real.

The idea is to start with 19 poems written in 2023, which cannot be in Open AI's database.  Therefore, Open AI cannot "know" that they are real poems.  We then take the first 80 characters of each poem, and ask Open AI to extend it to become a longer poem.

Thus, suppose we start with a pre-2023 poem, for the sake of having a more familiar example:

Two roads diverged in a yellow wood,
And sorry I could not travel both

The correct extension of the poem is:

Two roads diverged in a yellow wood,
And sorry I could not travel both
And be one traveler, long I stood
And looked down one as far as I could
To where it bent in the undergrowth;

GPT provides the following creative extension:

Two roads diverged in a yellow wood,
And sorry I could not travel both
Yet each beckoned with a promise to explore,
One bathed in sunlight, the other veiled in shadow's oath.
In contemplation, I stood at the crossroads' core.

Now the two versions of the poem - Frost's and GPT's - would become training data for a fine tuning job.  The fine tuning would start from the model gpt-3.5-turbo and would modify it so as to be especially proficient at distinguishing the two verisons.  The new model, when asked which poem (Frost's or GPT's) is written by a real poet, would be likely to get the right answer.  By feeding many test cases into the fine tuning job, we make it more likely that the fine-tuned model can guess a wide variety of poems.

I'll note that the "real" poems contain a significant amount of profanity, as modern poems are wont to do.  This does not affect that user-viewed output of the model, which simply judges 0 or 1, AI-generated or real poet.  Nevertheless, I wanted to practice removing the profanity from the poems, so I have done so.  In real applications of LLMs, all kinds of data are possible, and one must be careful about what the user can see.

I am only using 20 training cases and 18 validation cases, because the bank of poems I found is small.  If I were to do this more seriously, I would want at least 50 training cases, ideally more.

I have suggested to the model that the number of cliches in the poem is a good clue toward its authenticity.  I noticed that GPT-generated poems tend to be full of cliches.  When I left this instruction out, GPT was not able to reliably distinguish between authentic and inauthentic poems.  In real applications, it is important to use domain knowledge and not just rely on models to figure everything out "from scratch."

There is an open question as to how much of the work is being done by the fine tuning, and how much is being done by the instruction to search for cliches.  I will leave this question for future work.

In any case, the fine tuned model is extremely accurate; it gets only one wrong answer out of 18 validation cases.  I've also checked it with a few poems that I wrote (which it can often mark as AI/amateur) and a few real poems external to the data set (which it seems to mark as "real poet.")  With real poems written prior to 2022, there is a concern that it is simply noting that this is a known poem written by Robert Frost.

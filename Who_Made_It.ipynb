{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f732676e-38be-4b1c-b03c-d872c50f5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from better_profanity import profanity\n",
    "import hashlib\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import logging\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import configparser\n",
    "import time\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16c86a65-122c-46c5-bca0-a0c95f9a84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "OPENAI_MODEL = config['DEFAULT']['OpenAIModel']\n",
    "FILENAME_JSONL = config['DEFAULT']['FilenameJsonl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "057c2ff6-328d-4453-a0b6-0c12c731bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_openai_client():\n",
    "    \"\"\"Returns an open ai client\"\"\"\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\", False)\n",
    "    if api_key:\n",
    "        return OpenAI(api_key=api_key)\n",
    "    else:\n",
    "        print(\"PROBLEM: no OPENAI_API_KEY in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b90f1d0f-31cd-43eb-a912-3c1cb6336681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoemList:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_realpoemlist(self):\n",
    "        \"\"\"Get a list of about 20 real poems from the given website.  Censor the poems.\"\"\"\n",
    "        poemlist_uncensored = list()\n",
    "        \n",
    "        with urlopen('https://bestofthenetanthology.com/2023-2/poetry2023/') as response:\n",
    "            soup = BeautifulSoup(response, 'html.parser')\n",
    "            for par in soup.find_all('p'):\n",
    "                for anchor in par.find_all('a'):\n",
    "                    if(re.match(\".*https://bestofthenetanthology.com/2023-2/poetry2023/.*\", anchor.get('href'))):\n",
    "                        with urlopen(anchor.get('href')) as response2:\n",
    "                            soup2 = BeautifulSoup(response2, 'html.parser')\n",
    "                            delimiter = \"\\n\"\n",
    "                            for line_break in soup2.findAll('br'):       # loop through line break tags\n",
    "                                line_break.replaceWith(delimiter)\n",
    "                            textlist = \"\"\n",
    "                            for par in soup2.find_all('p'):\n",
    "                                textlist = textlist + \"\\n\" + par.text\n",
    "                            poemlist_uncensored.append(textlist)\n",
    "            self.realpoemlist = [profanity.censor(x) for x in poemlist_uncensored]\n",
    "    \n",
    "    def get_fakepoemlist(self, openai_client, openai_model: str = OPENAI_MODEL):\n",
    "        \"\"\" Get a list of fake poems, one for each real poem.\n",
    "        The fake poems have the same first 80 characters of the real poems, but then Open AI writes the rest of the poem itself.\n",
    "        This tends to produce poems with cliches, which are picked up by the model.\n",
    "        \n",
    "        Arguments:\n",
    "        openai_client -- an OpenAI client used to extent the real poems into fake poems.\n",
    "        openai_model -- The model used for the extension.\n",
    "        \"\"\"\n",
    "        self.fakepoemlist = list()\n",
    "        n = 0\n",
    "        max_n = len(self.realpoemlist) - 1\n",
    "        for poem in self.realpoemlist:\n",
    "            start = poem[0:80]\n",
    "            query = f\"\"\"\n",
    "            Please complete the following poem's beginning.  Start with this string of characters, then add to it to write a poem of about 300\n",
    "            characters.  The given string:\n",
    "            -------\n",
    "            {start}\n",
    "            \"\"\"\n",
    "            chat_completion = openai_client.chat.completions.create(\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": query,\n",
    "                    }\n",
    "                ],\n",
    "                model=openai_model,\n",
    "            )\n",
    "            fakepoem = chat_completion.choices[0].message.content\n",
    "            self.fakepoemlist.append(poem[0:80] + fakepoem)\n",
    "            n += 1\n",
    "            if n > max_n:\n",
    "                break\n",
    "\n",
    "    def write_poems_to_jsonl(self):\n",
    "        \"\"\"Create JSONL training file with the first N poems and the first N fake poems\"\"\"\n",
    "        lst = list()\n",
    "        N = 9\n",
    "        for poem in self.realpoemlist[0:N]:\n",
    "            msg = {\"messages\": [{\"role\": \"system\", \"content\": \"You want to write 0 if a poem is written by AI and 1 if written by a human.  This usually means to write a 0 if there are cliches, and 1 if there are few or no cliches in the writing.\"}, {\"role\": \"user\", \"content\": poem}, {\"role\": \"assistant\", \"content\": \" 1\"}]}\n",
    "            lst.append(json.dumps(msg))\n",
    "        for fakepoem in self.fakepoemlist[0:N]:\n",
    "            msg = {\"messages\": [{\"role\": \"system\", \"content\": \"You want to write 0 if a poem is written by AI and 1 if written by a human.  This usually means to write a 0 if there are cliches, and 1 if there are few or no cliches in the writing.\"}, {\"role\": \"user\", \"content\": fakepoem}, {\"role\": \"assistant\", \"content\": \" 0\"}]}\n",
    "            lst.append(json.dumps(msg))\n",
    "        random.shuffle(lst)\n",
    "        with open(FILENAME_JSONL, \"w\") as file:\n",
    "            for elt in lst:\n",
    "                file.write(elt + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec120dc-4918-4a0e-b4f5-d4686f3c2ef8",
   "metadata": {},
   "source": [
    "### I had to tell it explicitly that cliches were a key element in determining AI or human writing; without that, it couldn't do the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30771ebc-e7c0-49a5-9326-d9b4909ac993",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuningJob:\n",
    "\n",
    "    def __init__(self, openai_client, filename: str = FILENAME_JSONL, openai_model: str = OPENAI_MODEL):\n",
    "        \"\"\"Creates a fine tuning job based on the jsonl file from PoemList.write_poems_to_jsonl\n",
    "        The name of the model is returned in self.model\n",
    "\n",
    "        Arguments:\n",
    "        openai_client -- A client for the fine tuning job\n",
    "        filename -- The jsonl file that contains the training data\n",
    "        openai_model -- The initial model that will be fine tuned\n",
    "        \"\"\"\n",
    "        \n",
    "        self._file_object = openai_client.files.create(\n",
    "            file=open(filename, \"rb\"),\n",
    "            purpose=\"fine-tune\"\n",
    "        )\n",
    "        self._fine_tuning_job = openai_client.fine_tuning.jobs.create(\n",
    "            training_file=self._file_object.id,\n",
    "            model=openai_model\n",
    "        )\n",
    "        self.model = None\n",
    "        s = 0\n",
    "        while self.model is None:\n",
    "            time.sleep(10)\n",
    "            s += 10\n",
    "            print(\"Waiting for fine tuning job to finish.  Seconds:\", s)\n",
    "            self.model = openai_client.fine_tuning.jobs.retrieve(self._fine_tuning_job.id).fine_tuned_model\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6d9f766-4742-4916-90de-5003aec9bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_poem(poem, openai_client, ftj_model: str) -> str:\n",
    "    \"\"\" Tests a poem to see if it's written by an AI or by a real poet.\n",
    "    Arguments:\n",
    "    poem -- The text of the poem\n",
    "    openai_client -- The Open AI client for the test\n",
    "    ftj_model -- The model from the fine tuning job that will be used for the test\n",
    "    \"\"\"\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=ftj_model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You want to write 0 if a poem is written by AI and 1 if written by a human.  This usually means to write a 0 if there are cliches, and 1 if there are few or no cliches in the writing.\"},\n",
    "            {\"role\": \"user\", \"content\": poem}\n",
    "        ]\n",
    "    )\n",
    "    return \"Written by a real poet\" if \"1\" in response.choices[0].message.content else \"Written by AI or amateur\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dea46f5-346d-4548-8e01-846ceb3b7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for fine tuning job to finish.  Seconds: 10\n",
      "Waiting for fine tuning job to finish.  Seconds: 20\n",
      "Waiting for fine tuning job to finish.  Seconds: 30\n",
      "Waiting for fine tuning job to finish.  Seconds: 40\n",
      "Waiting for fine tuning job to finish.  Seconds: 50\n",
      "Waiting for fine tuning job to finish.  Seconds: 60\n",
      "Waiting for fine tuning job to finish.  Seconds: 70\n",
      "Waiting for fine tuning job to finish.  Seconds: 80\n",
      "Waiting for fine tuning job to finish.  Seconds: 90\n",
      "Waiting for fine tuning job to finish.  Seconds: 100\n",
      "Waiting for fine tuning job to finish.  Seconds: 110\n",
      "Waiting for fine tuning job to finish.  Seconds: 120\n",
      "Waiting for fine tuning job to finish.  Seconds: 130\n",
      "Waiting for fine tuning job to finish.  Seconds: 140\n",
      "Waiting for fine tuning job to finish.  Seconds: 150\n",
      "Waiting for fine tuning job to finish.  Seconds: 160\n",
      "Waiting for fine tuning job to finish.  Seconds: 170\n",
      "Waiting for fine tuning job to finish.  Seconds: 180\n",
      "Waiting for fine tuning job to finish.  Seconds: 190\n",
      "Waiting for fine tuning job to finish.  Seconds: 200\n",
      "Waiting for fine tuning job to finish.  Seconds: 210\n",
      "Waiting for fine tuning job to finish.  Seconds: 220\n",
      "Waiting for fine tuning job to finish.  Seconds: 230\n",
      "Waiting for fine tuning job to finish.  Seconds: 240\n",
      "Waiting for fine tuning job to finish.  Seconds: 250\n",
      "Waiting for fine tuning job to finish.  Seconds: 260\n",
      "Waiting for fine tuning job to finish.  Seconds: 270\n",
      "Waiting for fine tuning job to finish.  Seconds: 280\n",
      "Waiting for fine tuning job to finish.  Seconds: 290\n",
      "Waiting for fine tuning job to finish.  Seconds: 300\n",
      "Waiting for fine tuning job to finish.  Seconds: 310\n",
      "Waiting for fine tuning job to finish.  Seconds: 320\n",
      "Waiting for fine tuning job to finish.  Seconds: 330\n",
      "Waiting for fine tuning job to finish.  Seconds: 340\n",
      "Waiting for fine tuning job to finish.  Seconds: 350\n",
      "Waiting for fine tuning job to finish.  Seconds: 360\n",
      "Waiting for fine tuning job to finish.  Seconds: 370\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "openai_client = generate_openai_client()\n",
    "poemlist = PoemList()\n",
    "poemlist.get_realpoemlist()\n",
    "poemlist.get_fakepoemlist(openai_client)\n",
    "poemlist.write_poems_to_jsonl()\n",
    "ftj = FineTuningJob(openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d13fca6e-5fd8-4fdc-8075-c14addc8b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This poem was written by ChatGPT\n",
    "openai_poem = \"\"\"In a land of whimsy, under a candy-coated sky, \n",
    "Where laughter flowed like rivers, and pigs knew how to fly. \n",
    "A quirky tale unfolds, in rhyme and jest, \n",
    "A silly little poem, just for your zest.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f978e1b5-dfda-4ee4-b305-8403788fc4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Written by AI or amateur'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem(openai_poem, openai_client, ftj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7660766a-45a4-4127-af25-2270ff51eae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This poem was written by me\n",
    "my_poem = \"\"\"This is a poem.  Yes it is.  It is not a very good one.  Oh no it is not.  \n",
    "But it is about butterflies, trees, and mountains.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53a6982a-85ab-43d1-81e4-d55e21ebc9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Written by AI or amateur'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem(my_poem, openai_client, ftj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "585dc03d-905d-40dc-93af-193f80cbbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was written by a real poet.\n",
    "real_poem = \"\"\"The bud\n",
    "stands for all things,\n",
    "even for those things that don't flower,\n",
    "for everything flowers, from within, of self-blessing;\n",
    "though sometimes it is necessary\n",
    "to reteach a thing its loveliness,\n",
    "to put a hand on its brow\n",
    "of the flower\n",
    "and retell it in words and in touch\n",
    "it is lovely\n",
    "until it flowers again from within, of self-blessing;\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08438578-19f6-4da9-b0c3-143fb13e850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Written by a real poet'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem(real_poem, openai_client, ftj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d0ed9f5d-a9a0-4e61-826c-f0bd23419dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n",
      "Written by a real poet\n"
     ]
    }
   ],
   "source": [
    "# All of these were written by real poets.\n",
    "for poem in poemlist.realpoemlist[10:]:\n",
    "    print(test_poem(poem, openai_client, ftj.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4ed1416-eba0-494a-9abd-0c1c1928f78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written by AI or amateur\n",
      "Written by AI or amateur\n",
      "Written by a real poet\n",
      "Written by AI or amateur\n",
      "Written by AI or amateur\n",
      "Written by AI or amateur\n",
      "Written by AI or amateur\n",
      "Written by AI or amateur\n",
      "Written by AI or amateur\n"
     ]
    }
   ],
   "source": [
    "# All of these were written by AI.\n",
    "for poem in poemlist.fakepoemlist[10:]:\n",
    "    print(test_poem(poem, openai_client, ftj.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be1330f2-fac0-4872-bad1-ca03ad3605fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some runs of this code, GPT thinks a real poet wrote this.  Other times, it realizes it is a fake.\n",
    "silly_poem = \"\"\"Sassafrass purple guppy monkey silly water box trapeze artist giraffe monsters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba90638e-1c28-4da1-be38-b0a2173f6189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Written by AI or amateur'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_poem(silly_poem, openai_client, ftj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23500780-bda3-4f64-8523-e7d1a8ff2cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Written by a real poet'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frost_poem = \"\"\"Two roads diverged in a yellow wood,\n",
    "And sorry I could not travel both\n",
    "And be one traveler, long I stood\n",
    "And looked down one as far as I could\n",
    "To where it bent in the undergrowth;\"\"\"\n",
    "test_poem(frost_poem, openai_client, ftj.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de81ca-64ca-4fd6-9edc-b02b958ca456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
